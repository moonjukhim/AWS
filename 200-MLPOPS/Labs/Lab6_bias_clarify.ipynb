{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker model bias monitor: Fairness and explainability with SageMaker Clarify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Clarify helps improve your machine learning models by detecting potential bias and helping explain how these models make predictions. The fairness and explainability functionality provided by Clarify takes a step towards helping you to build trustworthy and understandable machine learning models. The product comes with the tools to help you with the following tasks:\n",
    "\n",
    "- Measure biases that can occur during each stage of the machine learning (ML) lifecycle (data collection, model training and tuning, and monitoring of ML models deployed for inference).\n",
    "- Generate model governance reports targeting risk and compliance teams and external regulators.\n",
    "- Provide explanations of the data, models, and monitoring used to assess predictions.\n",
    "\n",
    "In this lab exercise, the production model and SageMaker endpoint is already deployed. You will use SageMaker Clarify to analyze the training dataset and validation datasets, measuring the pre-training bias of a dataset and post-training bias of a model. Finally, you will generate and review an explainability report on the importance of the various input features on the modelâ€™s decision.\n",
    "\n",
    "\n",
    "![MLOPS Amazon Clarify architecture](images/ClarifySDK.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and configurations\n",
    "\n",
    "Run the following cell to import the required Python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from sagemaker import get_execution_role, image_uris, Session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "from sagemaker.model_monitor import (\n",
    "    BiasAnalysisConfig,\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelBiasMonitor,\n",
    "    ModelExplainabilityMonitor,\n",
    ")\n",
    "\n",
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to determine the full name of the modelArtifactBucket for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = ''\n",
    "s3 = boto3.resource('s3')\n",
    "for buckets in s3.buckets.all():\n",
    "    if 'modelartifactbucket' in buckets.name:\n",
    "        bucket = buckets.name\n",
    "\n",
    "print(f\"Bucket Name: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to prepopulate SageMaker production endpoint name and production model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get production endpoint name\n",
    "endpoint_name = boto3.Session().client('sagemaker').list_endpoints(SortBy='CreationTime')['Endpoints'][0]['EndpointName']\n",
    "\n",
    "# Get production model name\n",
    "model_name = boto3.Session().client('sagemaker').list_models(SortBy='CreationTime')['Models'][0]['ModelName']\n",
    "\n",
    "# Check if the endpoint is in service\n",
    "client = boto3.client('sagemaker')\n",
    "result = False\n",
    "while result is False:\n",
    "    response = client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    if (response['EndpointStatus'] == 'InService'):\n",
    "        print(f\"Production Endpoint Name:{endpoint_name}\")\n",
    "        print(f\"Production Model Name:{model_name}\")\n",
    "        result = True\n",
    "    else:\n",
    "        print(\"Waiting for endpoint to be active\")\n",
    "        time.sleep(5)\n",
    "        result = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to get the required IAM Role and AWS Region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "print(f\"RoleArn: {role}\")\n",
    "\n",
    "sagemaker_session = Session()\n",
    "sagemaker_client = sagemaker_session.sagemaker_client\n",
    "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(f\"AWS region: {region}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to create an Amazon S3 path for storing captured data and reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'sagemaker'\n",
    "s3_key = f\"s3://{bucket}/{prefix}\"\n",
    "print(f\"S3 key: {s3_key}\")\n",
    "\n",
    "code_prefix = '{}/code'.format(prefix)\n",
    "data_capture_prefix = f'{prefix}/datacapture'\n",
    "s3_capture_upload_path = f'{s3_key}/datacapture'\n",
    "s3_report_path = f'{s3_key}/reports'\n",
    "\n",
    "print(f\"Capture path: {s3_capture_upload_path}\")\n",
    "print(f\"Report path: {s3_report_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to read the train and validate data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = \"data/validate.csv\"\n",
    "train_dataset = \"data/train.csv\"\n",
    "dataset_type = \"text/csv\"\n",
    "\n",
    "with open(train_dataset) as f:\n",
    "    headers_line = f.readline().rstrip()\n",
    "all_headers = headers_line.split(\",\")\n",
    "label_header = all_headers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing endpoint with sample traffic\n",
    "\n",
    "Run the following code to extract a subset of samples from the validate datasets, and write the sample data as a local csv file. You will have two sets of files:\n",
    "\n",
    "- data-test.csv contains only the feature data. \n",
    "- data-test-label.csv contains the label and feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are randomly picking subset of data from test datasets.\n",
    "import itertools\n",
    "\n",
    "shape = pd.read_csv(test_dataset)\n",
    "\n",
    "a = [10*i for i in range(3)]\n",
    "b = [10+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data = shape.drop(shape.columns[[0]],axis=1)\n",
    "test_data = test_data.iloc[indices]\n",
    "test_data_with_label = shape.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"data/data-test.csv\",index=False,header=False)\n",
    "test_data_with_label.to_csv(\"data/data-test-label.csv\",index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to perform the prediction. You will use the sample dataset you populated in the previous steps as a payload. At the end of the run, you will see the prediction as \"0\" or \"1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke Endpoint with test data for a quick test\n",
    "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "predictions = ''\n",
    "\n",
    "with open('data/data-test.csv', 'r') as f:\n",
    "    for row in f:\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        payload = row.rstrip('\\n')\n",
    "        response = sagemaker_runtime_client.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                   ContentType=\"text/csv\",\n",
    "                                   Body=payload)\n",
    "        predictions = ','.join([predictions, response['Body'].read().decode('utf-8')])\n",
    "        time.sleep(0.5)\n",
    "\n",
    "predictions = predictions.replace('\\n','')\n",
    "predictions = predictions.split(\",\")\n",
    "predictions.pop(0)\n",
    "print(\"=\"*20)\n",
    "print(predictions)\n",
    "print(\"Done!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View captured data\n",
    "\n",
    "Run the following code to list the data capture files stored in S3. You should expect to see different files from different time periods organized based on the hour in which the invocation occurred. Rerun the cell if you see failure logs in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting 2 minutes for file to load...\")\n",
    "time.sleep(120)\n",
    "s3_client = boto3.Session().client('s3')\n",
    "current_endpoint_capture_prefix = '{}/{}'.format(data_capture_prefix, endpoint_name)\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get('Contents')]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\ns3://\"+bucket+str(capture_files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to view the contents of a single capture file. Here, you should see all the data captured in a SageMaker specific JSON formatted file. Take a quick peek at the first few lines in the captured file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get('Body').read().decode(\"utf-8\")\n",
    "\n",
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(capture_file[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to view content of a single line in the formatted JSON object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(json.loads(capture_file.split('\\n')[0]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Clarify setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to use the SageMaker Clarify processor.\n",
    "\n",
    "The Clarify processor is setting up the infrastructure that will be used to run the bias detection on a distributed cluster.  In this example, there is only one instance in the cluster. To learn more about Clarify configuration, see [Configure an Amazon SageMaker Clarify Processing Jobs for Fairness and Explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-configure-processing-jobs.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import clarify\n",
    "clarify_processor = clarify.SageMakerClarifyProcessor(role=role,\n",
    "                                                      instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge',\n",
    "                                                      sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to upload the test and train datasets to S3. The _train_uri_ and _test_uri_ will be used to directly pull data from S3, writing the dataconfig and modelconfig in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_uri = S3Uploader.upload('data/train.csv', 's3://{}/{}'.format(bucket, prefix))\n",
    "train_input = TrainingInput(train_uri, content_type='csv')\n",
    "test_uri = S3Uploader.upload('data/validate.csv', 's3://{}/{}'.format(bucket, prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting bias\n",
    "\n",
    "#### SageMaker Clarify helps you detect possible pre- and post-training biases using a variety of metrics.\n",
    "\n",
    "### Writing DataConfig and ModelConfig\n",
    "\n",
    "A **DataConfig** object communicates some basic information about data I/O to Clarify. You will specify where to find the input dataset, where to store the output, the target column (label), the header names, and the dataset type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to define DataConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path = 's3://{}/{}/clarify-bias'.format(bucket, prefix)\n",
    "bias_data_config = clarify.DataConfig(s3_data_input_path=train_uri,\n",
    "                                      s3_output_path=bias_report_output_path,\n",
    "                                      label='Churn',\n",
    "                                      headers=all_headers,\n",
    "                                      dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **ModelConfig** object communicates information about your trained model. To avoid additional traffic to your production models, Clarify sets up and tears down a dedicated endpoint when processing.\n",
    "\n",
    "- **instance_type** and **instance_count** specify the preferred instance type and instance count used to run your model while processing in Clarify. The testing dataset is small so a single standard instance is good enough to run this example. If you have a large and complex dataset, you might want to use a better instance type to speed it up, or add more instances to enable Spark parallelization.\n",
    "\n",
    "- **accept_type** denotes the endpoint response payload format, and **content_type** denotes the payload format of request to the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to define ModelConfig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = clarify.ModelConfig(model_name=model_name,\n",
    "                                   instance_type='ml.m5.xlarge',\n",
    "                                   instance_count=1,\n",
    "                                   accept_type='text/csv',\n",
    "                                   content_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **ModelPredictedLabelConfig** provides information on the format of your predictions. You are using the binary classification for this problem. The random forest model gives you the probabilities of samples, so Clarify invokes the endpoint, and then it uses probability_threshold to convert the probability to binary labels for bias analysis. Prediction above the threshold is interpreted as label value 1, and below or equal to the threshold is interpreted as label value 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to define ModelPredictedLabelConfig for clarify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_config = clarify.ModelPredictedLabelConfig(probability_threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing BiasConfig\n",
    "Clarify also needs information on what the sensitive columns (facets) are, what the sensitive features (facet_values_or_threshold) may be, and what the desirable outcomes are (label_values_or_threshold). Clarify can handle both categorical and continuous data for facet_values_or_threshold and for label_values_or_threshold. In this case, you are using categorical data.\n",
    "\n",
    "This information is specified in the BiasConfig API. Here, the positive outcome is Churn = 0, _Account Length_ is a sensitive category, _Day Calls_ respondents is the sensitive group, and _group_name_ is used to form subgroups for the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_config = clarify.BiasConfig(label_values_or_threshold=[0],\n",
    "                                facet_name='Account Length',\n",
    "                                facet_values_or_threshold=[100],\n",
    "                                group_name='Day Calls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Pre-training bias**\n",
    "\n",
    "Bias can be present in your data before any model training occurs. Inspecting your data for bias before training begins can help detect any data collection gaps, inform your feature engineering, and hep you understand what societal biases the data may reflect.\n",
    "\n",
    "Computing pretraining bias metrics does not require a trained model.\n",
    "\n",
    "#### **Post-training bias**\n",
    "\n",
    "Computing post-training bias metrics does require a trained model.\n",
    "\n",
    "Unbiased training data (as determined by concepts of fairness measured by bias metrics) may still result in biased model predictions after training. Whether this occurs depends on several factors, including hyperparameter choices.\n",
    "\n",
    "You can run these options separately with run_pre_training_bias() and run_post_training_bias() or at the same time with run_bias() as shown in the following run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to start the Clarify processor for evaluation. It typically takes 10 minutes to complete the Clarify run. Clarify creates an ephemeral SageMaker endpoint for compute and deletes the resource once the calculation is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_bias(data_config=bias_data_config,\n",
    "                           bias_config=bias_config,\n",
    "                           model_config=model_config,\n",
    "                           model_predicted_label_config=predictions_config,\n",
    "                           pre_training_methods='all',\n",
    "                           post_training_methods='all')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the run is complete, let's review the bias report.\n",
    "\n",
    "#### **Viewing the bias report**\n",
    "\n",
    "In Studio, you can view the results under the **Experiments** tab.\n",
    "\n",
    "1. In the left pane, choose on **Home** > **Experiments** > **Unassigned runs**.\n",
    "\n",
    "1. Open (double-click) the trial with a name that contains **Clarify-Bias**.\n",
    "\n",
    "  The bias report will open in a new tab. After you have reviewed it, you will need to return to this tab (the tab labled *model_bias_clarify.ipynb*) to view the remaining instructions.\n",
    "\n",
    "1. In the new tab that opens, select **bias report** to review the report.\n",
    "\n",
    "<img src=\"./recordings/bias_report.gif\">\n",
    "\n",
    "Each bias metric has detailed explanations with examples that you can explore. Here are a few metrics to review.\n",
    "\n",
    "- **Class Imbalance(CI):** Detects if the advantaged group is represented in the dataset at a substantially higher rate than the disadvantaged group, or vice versa.\n",
    "- **Total Variation Distance (TVD):** This measure of distance in label distributions is half the Hamming distance between the probability distribution of labels of the advantaged class and the probability distribution of the disadvantaged class.\n",
    "- **Conditional Demographic Disparity in Predicted Labels (CDDPL):** The metric examines whether the model predicted a bigger proportion of rejected outcomes for the disadvantaged class than the proportion of accepted outcomes for the same class.\n",
    "\n",
    "<img src=\"./recordings/bias_detail.gif\">\n",
    "\n",
    "You could also summarize the results in a handy table. Choose the **table** icon on the right side of the page.\n",
    "\n",
    "<img src=\"./recordings/bias_report_chart.gif\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may view the bias repot (formatted as a pdf, html, and ipynb a file), in the following S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_report_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining predictions\n",
    "\n",
    "There are expanding business needs and legislative regulations that require explanations of why a model made the decision it did. SageMaker Clarify uses SHapley Additive exPlanations (SHAP) to explain the contribution that each input feature makes to the final decision. SHAP analyzes, for each data instance, the individual contribution of feature values to the predicted output, and it represents them as a positive or negative value.\n",
    "\n",
    "The Kernel SHAP algorithm requires a baseline (also known as background dataset). Baseline dataset type must be the same as dataset_type of DataConfig, and baseline samples must only include features. By definition, the baseline dataset should either be an S3 URI to the baseline dataset file or an in-place list of samples. In this case, you chose the latter, and put the first sample of the test dataset to an in-place list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to add SHAP configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_config = clarify.SHAPConfig(baseline=[test_data.iloc[0].values.tolist()],\n",
    "                                 num_samples=15,\n",
    "                                 agg_method='mean_abs',\n",
    "                                 save_local_shap_values=False)\n",
    "\n",
    "explainability_output_path = 's3://{}/{}/clarify-explainability'.format(bucket, prefix)\n",
    "explainability_data_config = clarify.DataConfig(s3_data_input_path=train_uri,\n",
    "                                s3_output_path=explainability_output_path,\n",
    "                                label='Churn',\n",
    "                                headers=all_headers,\n",
    "                                dataset_type='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to start Clarify and evaluate explainability. It typically takes 10 minutes to complete the task.\n",
    "\n",
    "While you are waiting for the process to complete, you can learn more about [Clarify fairness and explainability](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-fairness-and-explainability.html) here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_processor.run_explainability(data_config=explainability_data_config,\n",
    "                                     model_config=model_config,\n",
    "                                     explainability_config=shap_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the run is complete, let's review the explainability report.\n",
    "\n",
    "#### Viewing the explainability report\n",
    "\n",
    "As with the bias report, you can view the explainability report in SageMaker Studio.\n",
    "\n",
    "1. In the left pane, choose **Home** > **Experiments** > **Unassigned runs**.\n",
    "\n",
    "1. Select the name with **Clarify-Explainability**.\n",
    "\n",
    "#### **Question:** Based on the report, which feature has the highest importance in determining the churn prediction?\n",
    "\n",
    "You may view the bias report (formatted as PDF, HTML, or ipynb) in the following S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainability_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "Finally, don't forget to clean up the resources you set up and used for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e45558c452cedcb26631315a9b3b77e80a9c32d662ed25df58964b99bc5b9b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
