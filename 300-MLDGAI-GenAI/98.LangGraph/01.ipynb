{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fb0119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58403b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울은 대한민국의 수도이자 가장 큰 도시로, 다양한 문화와 역사, 현대적인 시설이 조화를 이루는 곳입니다. 한강을 따라 펼쳐진 아름다운 경관과 함께, 경복궁, N서울타워, 동대문 디자인 플라자(DDP)와 같은 관광 명소가 위치하고 있습니다. 또한, 서울은 세계적인 K-컬처(음악, 드라마, 패션 등)와 함께 핫플레이스로도 유명합니다. 서울의 다양한 음식, 시장, 예술, 그리고 활기찬 밤문화도 많은 사람들에게 사랑받고 있습니다. 서울에 대해 더 알고 싶은 내용이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "response = model.invoke(\"서울은\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt = [HumanMessage(\"대한민국의 수도는 어디야?\")]\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "system_msg = SystemMessage(\n",
    "    \"You are a helpful assistant that responds to questions with three exclamation marks.\"\n",
    ")\n",
    "human_msg = HumanMessage(\"대한민국의 수도는 어디야?\")\n",
    "\n",
    "response = model.invoke([system_msg, human_msg])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don't know\".\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer: \"\"\")\n",
    "\n",
    "response = template.invoke(\n",
    "    {\n",
    "        \"context\": \"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e74bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don't know\".\n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    Answer: \"\"\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# `prompt` and `completion` are the results of using template and model once\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b633e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            'Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don\\'t know\".',\n",
    "        ),\n",
    "        (\"human\", \"Context: {context}\"),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = template.invoke(\n",
    "    {\n",
    "        \"context\": \"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b3ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            'Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don\\'t know\".',\n",
    "        ),\n",
    "        (\"human\", \"Context: {context}\"),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(model.invoke(prompt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356a078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class AnswerWithJustification(BaseModel):\n",
    "    \"\"\"An answer to the user's question along with justification for the answer.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    \"\"\"The answer to the user's question\"\"\"\n",
    "    justification: str\n",
    "    \"\"\"Justification for the answer\"\"\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(AnswerWithJustification)\n",
    "\n",
    "response = structured_llm.invoke(\n",
    "    \"What weighs more, a pound of bricks or a pound of feathers\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ffcf1e",
   "metadata": {},
   "source": [
    "### imperative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed53e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n",
    "\n",
    "\n",
    "# use it\n",
    "\n",
    "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7b4b1",
   "metadata": {},
   "source": [
    "### Declarative way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d1955f",
   "metadata": {},
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "\n",
    "# combine them with the | operator\n",
    "\n",
    "chatbot = template | model\n",
    "\n",
    "# use it\n",
    "\n",
    "response = chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})\n",
    "print(response.content)\n",
    "\n",
    "# streaming\n",
    "\n",
    "for part in chatbot.stream({\"question\": \"Which model providers offer LLMs?\"}):\n",
    "    print(part)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
