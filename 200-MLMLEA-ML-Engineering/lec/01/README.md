1️⃣ 데이터 편향 (Data Bias)

- ### 정의

    훈련 데이터가 특정 집단·상황·패턴을 과도하게 대표하거나, 반대로 중요 집단이 누락되어 발생하는 편향

- ### 발생 원인

    - 수집 단계에서의 불균형
    - 과거 데이터 자체가 이미 사회적 편향을 포함
    - 편의 표본(Convenience sampling)
    - 레이블 오류 또는 누락

- ### 실제 사례

    - 채용 AI가 남성 이력서를 더 높게 평가
    - 얼굴 인식 모델이 특정 인종에서 오류율 급증
    - 신용평가 모델이 금융 이력 부족 계층을 과도하게 저평가


2️⃣ 알고리즘 편향 (Algorithmic Bias)

- ### 정의


    데이터가 비교적 공정해 보여도,
    모델 구조, 목표 함수, 최적화 방식 때문에 특정 집단에 불리한 결과가 나오는 경우입니다.

- ### 실제 사례

    - 예제 1: 신용 점수 모델 : “지역”이 사실상 소득, 인종, 교육 수준의 대리 변수(proxy) 역할
    - 예제 2: 추천 알고리즘 : 알고리즘은 ‘공정’을 몰라서 숫자가 잘 나오는 방향으로만 움직임

3️⃣ 상호작용 편향 (Interaction Bias)

- ### 정의

    AI가 사람과 상호작용하면서 특정 집단의 목소리만 반영되거나 왜곡되는 편향

- ### 실제 사례

    - 예제 1: 챗봇 학습
    - 예제 2: 제품 피드백 시스템

4️⃣ 편향 증폭 (Bias Amplification)
    
- ### 정의

    이미 존재하는 사회적 편향이 AI를 통해 더 강해지고 반복되는 현상

- ### 실제 사례

    - 예제 1: 광고 타겟팅
    - 예제 2: 범죄 예측 시스템

---

| 편향 유형   | 핵심 원인      | 쉬운 요약           |
| ------- | ---------- | --------------- |
| 데이터 편향  | 학습 데이터 불균형 | “데이터부터 불공정”     |
| 알고리즘 편향 | 최적화 목표·설계  | “숫자만 보면 공정이 깨짐” |
| 상호작용 편향 | 사용자 참여 차이  | “말 많이 한 사람이 기준” |
| 편향 증폭   | 자동화·반복     | “기존 차별을 확대 재생산” |
